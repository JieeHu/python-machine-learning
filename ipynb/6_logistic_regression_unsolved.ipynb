{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  },
  "name": "",
  "signature": "sha256:06717ef46a4ac5e494b2a33e5efbe4b6a9bf4ded917c5e0f7e2d87174b597beb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Logistic regression\n",
      "\n",
      "In this session we will develop a simple implementation of Logistic Regression trained with SDG. The goal is to serve to promote the understanding of gradient descent, the logistic regression model and the practical use of numpy.\n",
      "\n",
      "First we'll load some toy data to use with our functions.  We'll make this into a binary problem by keeping only two species."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "iris = load_iris()\n",
      "\n",
      "\n",
      "data = iris.data[iris.target != 2]\n",
      "target = iris.target[iris.target != 2]\n",
      "X_train, X_val, y_train, y_val = train_test_split(data, target, \n",
      "                                                  test_size=1/3, random_state=123)\n",
      "scaler = StandardScaler()\n",
      "X_train = scaler.fit_transform(X_train)\n",
      "X_val = scaler.transform(X_val)\n",
      "\n",
      "print(X_train.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(66, 4)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Model definition\n",
      "\n",
      "\n",
      "We'll first define the interface of our model:\n",
      "\n",
      "- `predict` - use model to compute predicted classes on new examples\n",
      "- `predict_proba` - - use model to compute class probabilities \n",
      "- `fit` - train a model using training features and labels\n",
      "\n",
      "as well some auxiliary functions.\n",
      "\n",
      "\n",
      "### Exercise 6.1\n",
      "\n",
      "Define function `inverse_logit`. The mathematical formulation is:\n",
      "$$\n",
      "\\mathrm{logit}^{-1}(z) = \\frac{1}{1-\\exp(-z)}\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def inverse_logit(z):\n",
      "    #..................................\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(inverse_logit(0.5))\n",
      "print(inverse_logit(-10.0))\n",
      "print(inverse_logit(0.0))\n",
      "print(inverse_logit(700.0) == inverse_logit(1000.0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.622459331202\n",
        "4.53978687024e-05\n",
        "0.5\n",
        "True\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 6.2 \n",
      "\n",
      "Define function `predict_proba`, with two arguments:\n",
      "\n",
      "- dictionary of model parameters `{'w':w,'b':b}`, where `w` is an array of coefficients and `b` a scalar intercept\n",
      "- matrix of new the features of new examples `X`\n",
      "\n",
      "The function should return an array of probabilities of the positive class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def predict_proba(wb, X):\n",
      "    #...............................\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initial model parameters\n",
      "w = numpy.zeros((X_train.shape[1],))\n",
      "b = 0\n",
      "wb = {'w':w,'b':b}\n",
      "# Use this initial model for prediction\n",
      "p_pred = predict_proba(wb, X_val)\n",
      "print(X_val.shape)\n",
      "print(p_pred.shape)\n",
      "print(p_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(34, 4)\n",
        "(34,)\n",
        "[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
        "  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
        "  0.5  0.5  0.5  0.5]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 6.3\n",
      "Define function `predict` which takes the same input as `predict_proba` but returns the class labels (0 or 1) instead of probabilities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def predict(wb, X):\n",
      "    #.............................\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = predict(wb, X_val)\n",
      "print(X_val.shape)\n",
      "print(y_pred.shape)\n",
      "print(y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(34, 4)\n",
        "(34,)\n",
        "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our model interface is complete.\n",
      "\n",
      "## Training\n",
      "We will now implement the interface of the SGD training algorithm:\n",
      "\n",
      "- `fit` which takes initial model parameters and trains it for one iteration on the given training data\n",
      "\n",
      "We will start with an auxiliary function `update` which does a single step of SGD.\n",
      "\n",
      "\n",
      "### Exercise 6.5\n",
      "\n",
      "Define function `update` which is given a single training example, and first uses the `predict_proba` function to get the predicted probability of the positive class, and then updates the weights and the bias of\n",
      "the model depending on the difference between this probability and the actual target. \n",
      "\n",
      "The function is given these arguments:\n",
      "\n",
      "- `wb` - the model weights and bias\n",
      "- `x`  - the feature vector of the training example\n",
      "- `y`  - the class label of the training example\n",
      "- `eta`- learning rate\n",
      "\n",
      "The update should update the given parameters by implementing the following operations:\n",
      "$$\n",
      "\\mathbf{w}_{new} = \\mathbf{w}_{old} + \\eta(y-p_{pred})\\mathbf{x}\n",
      "$$\n",
      "\n",
      "and\n",
      "\n",
      "$$\n",
      "b_{new} = b_{old} + \\eta (y-p_{pred})\n",
      "$$\n",
      "\n",
      "Finally, the function should return the value of the loss for the current examples, that is:\n",
      "$$\n",
      "-y \\log_2(p_{pred}) - (1-y)\\log_2(1-p_{pred})\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update(wb, x, y, eta):\n",
      "    #.............................\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wb = {'w':numpy.zeros((X_train.shape[1],)), 'b':0}\n",
      "eta = 0.1\n",
      "# Show P(y=1) before and after update\n",
      "\n",
      "# Process example 1\n",
      "i = 0\n",
      "print(\"Actual class: {}\".format(y_train[i]))\n",
      "print(\"P(y=1): {}\".format(predict_proba(wb, X_train[i])))\n",
      "loss = update(wb, X_train[i], y_train[i], eta)\n",
      "print(\"Loss: {}\".format(loss))\n",
      "print(wb)\n",
      "print(\"P(y=1): {}\".format(predict_proba(wb, X_train[i])))\n",
      "\n",
      "\n",
      "print()\n",
      "# Process example 5\n",
      "i = 5\n",
      "print(\"Actual class: {}\".format(y_train[i]))\n",
      "print(\"P(y=1): {}\".format(predict_proba(wb, X_train[i])))\n",
      "loss = update(wb, X_train[i], y_train[i], eta)\n",
      "print(\"Loss: {}\".format(loss))\n",
      "print(wb)\n",
      "print(\"P(y=1): {}\".format(predict_proba(wb, X_train[i])))\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Actual class: 1\n",
        "P(y=1): 0.5\n",
        "Loss: 1.0\n",
        "{'w': array([-0.00510916, -0.00941896,  0.05861284,  0.06567975]), 'b': 0.050000000000000003}\n",
        "P(y=1): 0.5516358229211761\n",
        "\n",
        "Actual class: 0\n",
        "P(y=1): 0.47971066416492397\n",
        "Loss: 0.9426139576198866\n",
        "{'w': array([ 0.04832087, -0.00038221,  0.10706961,  0.12371601]), 'b': 0.0020289335835076}\n",
        "P(y=1): 0.42322549287358235\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 6.5 \n",
      "\n",
      "Define function `fit`, which will use the `update` function on each training example in turn, for a single iteration of SGD. The function takes the following arguments:\n",
      "\n",
      "- `wb` - the current model weights and bias\n",
      "- `X` - the matrix of training example features\n",
      "- `y` - the vector of training example classes\n",
      "- `eta=0.1` - the learning rate, with default 0.1\n",
      "\n",
      "The function return the sum of the losses on all the examples, as given by `update`.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def fit(wb, X, y, eta=0.01):\n",
      "    #..................................\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wb = {'w':numpy.zeros((4,)), 'b':0}\n",
      "eta = 0.01\n",
      "J = 10\n",
      "\n",
      "# Let's run 10 epochs of SGD\n",
      "print(\"epoch loss\")\n",
      "for j in range(J):\n",
      "    loss = fit(wb, X_train, y_train, eta=0.1)\n",
      "    print(\"{} {}\".format(j, loss))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch loss\n",
        "0 17.72577850862744\n",
        "1 4.627620670165031\n",
        "2 2.8222464100215396\n",
        "3 2.051384595317413\n",
        "4 1.6185531413141234\n",
        "5 1.3399609057910178\n",
        "6 1.1450792404910377\n",
        "7 1.0008464653084332\n",
        "8 0.8896489407032253\n",
        "9 0.8012216550285289\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 6.6\n",
      "\n",
      "Find a good combination of number of epochs and learning rate for your model, by checking the classification of accuracy on validation data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## SGD classifier \n",
      "\n",
      "SGD classifier is suitable to use on sparse data such as character or word ngram counts.\n",
      "\n",
      "We'll use the scikit-learn implementation of Logistic Regression with SGD to learn to classify posts on various discussion groups into topics.  There are twenty groups:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "data = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
      "for group in data.target_names:\n",
      "    print(group)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt.atheism\n",
        "comp.graphics\n",
        "comp.os.ms-windows.misc\n",
        "comp.sys.ibm.pc.hardware\n",
        "comp.sys.mac.hardware\n",
        "comp.windows.x\n",
        "misc.forsale\n",
        "rec.autos\n",
        "rec.motorcycles\n",
        "rec.sport.baseball\n",
        "rec.sport.hockey\n",
        "sci.crypt\n",
        "sci.electronics\n",
        "sci.med\n",
        "sci.space\n",
        "soc.religion.christian\n",
        "talk.politics.guns\n",
        "talk.politics.mideast\n",
        "talk.politics.misc\n",
        "talk.religion.misc\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data is in the form of raw text, so we'll need to extract some features from it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(data.data[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I was wondering if anyone out there could enlighten me on this car I saw\n",
        "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
        "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
        "the front bumper was separate from the rest of the body. This is \n",
        "all I know. If anyone can tellme a model name, engine specs, years\n",
        "of production, where this car is made, history, or whatever info you\n",
        "have on this funky looking car, please e-mail.\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will split the data into train and validation, and then extract word counts and bigram counts from the texts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text_train, text_val, y_train, y_val = train_test_split(data.data, data.target, test_size=1/3, random_state=123)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "vec = CountVectorizer(analyzer='word', ngram_range=(1,2), lowercase=True)\n",
      "X_train = vec.fit_transform(text_train)\n",
      "X_val = vec.transform(text_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now try the SGDClassifier on this data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = SGDClassifier(loss='log', random_state=666)\n",
      "\n",
      "#---------------------------------------\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.613202545069\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 6.7\n",
      "\n",
      "Experiment with different features and model hyperparameters, and find a well performing set"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}